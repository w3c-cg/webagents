# WebAgents CG: Regular Meeting (Aug 1, 2025)

## Agenda

   * Introduction
       * Introduction of new participants (if any)
       * Review minutes from the previous meeting
       * General CG updates
   * Invited Talk: Amit Chopra — Why Agentic AI Needs Interaction-Oriented Programming

## Participants

   * Amit Chopra
   * Andrei Ciortea
   * Joshua Cornejo
   * Soheil Roshankish
   * Önder Gürcan
   * Patrick Hochstenbach
   * Simon Mayer
   * Jérémy Lemée
   * Danai Vachtsevanou
   * Lorenzo Moriondo
   * Kai Schultz
   * Justus
   * Alessandro Ricci
   * Christian Glomb
   * Merlin Aupic
   * Dave Raggett
   * Terry Payne
   * Eric Drury
   * Dina

## Regrets

   * Rem Collier
   * Antoine Zimmermann
   * Ege Korkan

**Scribe**: Simon

**Notes from previous meeting**: [Link to meeting notes](https://github.com/w3c-cg/webagents/blob/main/Meetings/RegularMeetings/2025-07-04.md)

## Meeting Notes

Andrei welcomes everyone and specifically Amit ([Google Scholar profile](https://scholar.google.com/citations?user=xXhZVgwAAAAJ&hl=en&oi=ao)) - for his talk "Agentic AI Needs Interaction-Oriented Programming". 

Amit's Talk (see slides, here only additional notes)

- Agentic AI: What's really exciting is that LLMs now perform actions in the real world.

- In Agentic AI, the system's main function is executing a workflow

- We don't want to program the system. Rather, we want to chat - having the workflow being planned out as the program goes, including the dynamic generation of new agents

- But LLMs are unreliable (commitments! trust! accountability!) - hence, should we really rely on LLMs to act on behalf of the user?

- Goal behind IOP: Want to bring system design/programming closer to stakeholder intuitions, to allow programmers to focus on business logic

-  "We bring models into agentic AI - declarative models"

- "IOP changes the 'social state' of the world"

- The LLM is the "heart" of the agent, but it is guided by the IOP adaptors

- IOP can help with bringing "some quality to the engineering process"

Discussion

- About LLM-based agents creating and specifying interaction protocols - what are the inputs that go into such an agent (Danai)

   * - Unsure/early. Rather high-level inputs or requirements. Possibly an argumentation-oriented scenario where LLM agents act on behalf of the stakeholders. Deriving common sense based on statements by stakeholders. (Amit)
   * - So if stakeholders provide requirements in NL for a new protocol, do you see problems with continuously generating new protocols without reusing older protocols or their vocabulary? How would this affect the different types of agents? Does this introduce too much dynamics? (Danai)
   * - Why not have a library of protocols and pick from this library? This could resolve the problem! (Amit)
- What about the A2A protocol that is presented as complementary to MCP for A2A interaction. How do you see this working with IOP? (Andrei)

   * - A2A is quite client-server oriented with an orchestration flavor. But would surely fit somewhere; it's not specifying aspects as general as IOP would like it to, also too little formal specification (Amit)
   * - Relevant multi-agent interaction aspects, Interoperability Task Force should pick this up (Andrei)
- Suggested interaction with Nicoletta (Fornara) since there might be a lot of joint interests. Soheil can be a bridge.

- What about security? Since the proposal is role-based, an agent needs to be a full embodiment of a role. More fine-grained access control might be required. Related, is there too much coupling? Coupling: accept, instruct, etc. are all actions, not functions. Then, the price is coupled as well (slide 11). These concepts do not belong in the same dimensions. What would be needed is that only the key be passed. The demonstrated concepts are easy to show for small scenarios, but for large scenarios and in practice there is worry about the maintainability and evolvability - especially change management - of this approach (Joshua)

   * - Good point about security. Formal models are required, and this is what IOP provides. For the coupling, this is specific to this example where the price needs to be coupled (right?). For maintainability, if these aspects are expressed in low-level code rather than in a formalism as in IOP, this becomes even less maintainable. The alternative to the IOP formalism is to put everything into python. (Amit)
   * - But Java/C# etc. do have the mechanisms, e.g. to separate data transfer objects. Python was never intended to build solutions that run across thousands of users in an enterprise setting. The "magic" that was intended by several different developments over the past 20 years (UML-based programming, automatic code generation, etc.) were all pulled back by practicality. The challenge that is seen with IOP is still the coupling of roles to specific run-time functions (e.g., "seller" to "what are the exact items that may be sold") and this is not just coupling, it is security-relevant. (Joshua)
- Sorry, scribe did not get the three questions/comments by Önder, but here are Amit's responses:

   * - Amit is working on developing approaches where LLMs enact the protocols
   * - Users don't interact using these protocols directly (Amit refers to them as the principals), but the interaction between the agents is formal on the basis of IOP
   * - There should be less chance of prompt injection when communication happens on the basis of formal structures, hence IOP should also mitigate this problem
   * - LLMs are closed systems, they generate everything according to a plan. No worry about prompt injection in this sense.
- Interesting where different "symbolic guardrails" are being put to constrain LLMs' negative implications (e.g., unreliability): in-between agents with approaches such as IOP, into LLMs with knowledge-based context engineering (e.g., KAG), etc. (Simon)

- Many of the problems (including security...?) that were mentioned may indeed be overcome by such consciously placed guardrails (Lorenzo)
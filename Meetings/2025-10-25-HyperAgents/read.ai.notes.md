[Speaker 1]
Will be related to this question. So, in fact, this other three main questions for the report, right? So, what should be the role of the web conceptually? What are the relevant standards within energy also outside of the W3C? What are the standardization gaps? So, maybe another litmusters would be.

Can we produce a standard that can help with that NFP or not? So, if we talk about, yeah.

[Speaker 2]
So, if we talk about boarding stopped?

[Speaker 1]
So, if we talk about transparency, we might be able to produce standards that help if we talk about. Scalability.

Yeah, that's tricky, but it is about architectural design, so it might produce. Or group notes or best practices that might help. If you talk about adaptability of agents, I'm not so sure we can have.

So, do we agree with this as a little monsters? So, then, the passion for each of these NFPs, can we help with standardization?

Yep.

[Speaker 2]
Recording in progress.

[Speaker 3]
Now, AI. Now you miss the most important part.

[Speaker 1]
Yes, so this nability. So, thanks for these questions, um? Work.

And

[Speaker 4]
I mean. The test alone works because we could have a standard foreign agent architecture and help with adaptability. It is that it's not in scope.

[Speaker 5]
An age of the architecture are Thunder.

[Speaker 1]
The question would be, then it boils down to the W3C. So, is it something that the W3C should do?

If that makes sense?

So, so it's about web standards. But. Why not web, standard, or web agents? I mean, they are called web agents. Yeah, so actually. So, I was saying that when we talk about architectural patterns also from the discussion we had this morning, there are a few things that we might recommend for hyper media agents.

I would just not classify that under adaptability. Um, but if we find something that is relevant for adaptability, then we can edit the list. Some concrete direction for that.

[Speaker 4]
My concern wasn't adaptability. Okay, neither I'm in favor of. Necessarily adaptability in the vision of creating a standard for web agents. More like to understand? What is his openness isn't? Yep, what is the scope of W? Proceed could be a web page and architecture, but it's not our scope at the moment.

[Speaker 1]
So, um?

Scope. So, one example that we had was about situated agents, right? So a situated agent has to be able to perceive its environment. So, for instance, web sub would be OWCC recommendation that can help.

Be within scope. Also, I'm not sure if I would qualify situatedness as a function as a non-functional property.

It can be. Um, so our definition for situatedness that comes from the literature is here. Agent. To interact with its environment directly, so perception and action, and to respond in a timely fashion to sensory input.

Secretiveness.

Really a non-functional property.

[Speaker 4]
Um,

[Speaker 1]
The ability to interact with its environment directly. Is this function of a non-functional?

[Speaker 3]
It's. Embedded within the definition of agent in the first place. I can't.

[Speaker 6]
Imagination

[Speaker 3]
Isn't going to be perceiving its environment and acting

[Speaker 2]
Well agentic systems at the moment. Do they really perceive their environment?

[Speaker 3]
I'm one of my goals. I've been a few days is to really understand what egentic means when if it's not.

Well, I think it has the notion of autonomy, but then. It is perceiving the requirements of the user and is providing access to the user could chew horn. That definition. I guess

[Speaker 2]
It means there's some argument that you total use is a form of perception as well

[Speaker 1]
That you choose

[Speaker 2]
To be, is, you know?

Constantly monitoring.

[Speaker 5]
But

[Speaker 3]
If you think about that definition, which originally came from Rodney Brooks, it makes a lot of sense when you think that he was looking at the notion of robots as an economist systems rather than software agents. I think that's where it becomes a little blurred as software entities being agents as opposed to physical activity.

Hardware, that's autonomous, and a piece of software. Then you're probably on the right track as it being a general goal or a general.

[Speaker 2]
You know, the the?

Some of the descriptions on the dods and it says have discoverability. For example, make it possible for entities to discover the IDS for their entities. So does situating us make it possible for agents to sense and affect their environment or to understand their environment to interact with the environment?

Is that it's a design goal then

[Speaker 1]
That we should have

[Speaker 2]
It as a design go, so that should be one of the design goals in my head. Can you see it again? So the designer is situating. This should be a design goal because situating this drives the design drive is Central to the um, the situated agent architectural diagram that we're going to show in a few minutes. Yeah, but without, yeah, so I would agree with you

[Speaker 1]
Now. I come back to a point that Steven was raising. So, what is necessary? What is?

[Speaker 2]
The the the there is an argument that the use of tools can be considered as a form of some. Source can be seen as a sort of sensory. So, if you have a tool that does a Google query to get back a set of documents that are relevant to?

[Speaker 1]
Motion of situatedness. So, yeah, I

[Speaker 6]
Think this definition is missing something, though. The agent is in a situation right, and you mentioned the concept last week of there being a boundary assistant so? It's not just a kind of global thing out there on the web that.

Environment with a boundary, and there's some kind of local interactions, local knowledge, local information that affects Its Behavior. So, using

[Speaker 3]
Context.

[Speaker 6]
Context. Yeah, maybe.

[Speaker 1]
Yeah, but a

[Speaker 6]
Certain kind of context. No.

[Speaker 1]
Interchangeably use context and environment. Can be interchangeably. Use context and

[Speaker 2]
Environments.

[Speaker 3]
I'm just trying to understand it and the scope of the coding agents. So, when I'm using GitHub car file, it's aware of my terminal output, but probably it's within the scope of its task, because I'm not really sure that GitHub compilot and vs code IG I'm using is constantly monitoring its own environment. I believe it's monitoring the context of the.

[Speaker 6]
The understanding of an environment is elements and how it changes with respect to time or other factors. Also defined as the perception of the elements of the environment, considering time and space, the understanding of their meaning, and the prediction of their status in the near future.

What situatedness was about? Yeah.

Okay, slower this time, so I just lost my Monday. Reloading. Okay. The understanding of an environment is elements and how it changes with respect to time or other factors. As the perception of the elements in the environment, considering time and space, the understanding of their meaning, and the prediction of their status in the near future.

[Speaker 1]
The one that we have here.

Because time in there.

[Speaker 6]
Yeah, yeah,

[Speaker 1]
And time is actually the critical aspect that makes it a very strong definition.

[Speaker 6]
Doesn't sum up the awareness aspect.

[Speaker 7]
And get just a comment on that. It seems that the situation awareness is more about the perception. It does not include the action part, that situations, because.

[Speaker 2]
They're spawning in a timely fashion to sensor input is.

Don't I think this application dependent? Yeah.

[Speaker 3]
Reaction is relevant.

[Speaker 1]
The observation?

[Speaker 2]
Yep.

[Speaker 3]
So,

[Speaker 1]
So for me, it's more about not having blind agents. Yeah, right.

[Speaker 2]
So.

[Speaker 1]
In a way that is irrational, simply because they don't have. Or they don't react to it,

[Speaker 3]
But there is a little bit more because they behave in the way which the rational it may be related to the context. Yeah, so task specific context, but we are also probably talking here about its awareness about its environment where it's being executed. So, if I'm having the agent as a software and the software is being run in some kind of the Docker container, then this piece of the software should absorb its Docker container its environment and be able.

[Speaker 6]
Is actually, you know there for a reason to do something as actions have? Just random actions in the environment. The nature of the environment affects what it does. Achieve its goals.

[Speaker 3]
I mean, starting with articles achievable, given that environment, and then once, there's that. How does it then proceed to achieve those goals? Given whatever's in that environment, including other agents, Etc?

[Speaker 1]
Because I'm losing a bit of the focus, I'm sorry.

[Speaker 3]
No, no,

[Speaker 1]
No, no, it's three. We are discussing together. I think that the discussion shifted a bit. So, what is it that we want to achieve?

The list is the discussion, then if it should be on the list or not.

It's aware of. And also there is this multi Mobility now.

But I want to just ask a small question. The terms that you are showing on the website. So that because we just mentioned five minutes ago that we should also be covering. Yo, what? What I am seeing here? The first definition, are we assuming that all agents are autonomous? We don't assume some reactivations. For example, I see that current Asian TDI agents most directive, you tell it what to do. It's responding to start autonomous usually.

It can listen to the moment and then act on something they did. This kind of things recently, yeah. That all agents are really autonomous, or are we going to assume that there are reactivations for Activisions? In this group, do we care about non-autonomous agents since the group is? W3C autonomous agents on the web okay? Uh, making this document is only about. Or is meant to? Promote. But actually, so autonomy is a can of forms, right? So?

Essentially two definitions that I'm aware of that. Used in the community about autonomy. So, the one, the first one, is the one that came from Mike Woodridge. I think he revised it at some point. A system is autonomous if it can function without the intervention of people or other agents.

Thinking that then the problem with this definition that the community observed is that with this definition is very hard to differentiate between what is automated. What is really autonomous? So the current definition that I'm aware of that is probably accepted by the community is closer to the definition given by Castel Frankie, which is inspired from cognitive science and looks at autonomy as a relational notion.

It's between on entity X, whose autonomy is being evaluated.

Which is? Um, entity against which you evaluate the autonomy. Some function action goal. So, for instance, you can. Is an agent from its environment. If you have a person that is trapped in a prison, they are not very autonomous.

Its environment. In the environment, so its autonomy is very much constrained by.

Organization, how autonomous is it? From that organization, and this boils down to the Norms and policies that would authorities Behavior.

So, how the how dependent is an agent and another agent? To what he said before the coffee break. Here, autonomy here comes to the fact that Euro cast the Asian to do something, and it is up to that agent to respond to discipline store or not. Yeah, right?

Also discussed by customer Frankie, actually. So autonomy, for instance, to choose its own goals. Yeah, yeah, this. So, the autonomy is discussed also with respect to internal design. Yeah, so I brought this into table because you said that we should also cover agency. Yeah, yeah, but we have here. So, now, a few things, and I think it's a great point that you are raising.

In the scientific literature. Here is very much related to Brooks ideas from the mid 90s. Yeah, and also

[Speaker 3]
If I may and the reason why.

Seen as autonomous in the way. They then proceed based on that observation, so being reactive doesn't mean that they can't be autonomous, right. But then, how do I qualify the situation where you interact with something that reacts to my instruction? And I think that's where you're coming from that.

[Speaker 1]
Yeah, actually, this is what I wanted to go towards. For instance, with the line call, for example, so that's a reactive agent, right? In the end, it just it has. It has a LED, and then it has a photo voltage.

On a robot transport unit, because a line follower can.

The line. You can Implement an algorithm that allows you to find back the line so it is less constrained by the environment, so it is more autonomous than some other places. And when we think about the existing llm agents at the moment deployed on the internet, what can you say about? Do you think they are autonomy?

Maybe I think we should clarify this is what happens,

[Speaker 3]
But I'm worried we can get off topic here.

[Speaker 1]
Yep, but

[Speaker 3]
Actually saying, I just wanted to make a comment. I could see I could propose an argument where autonomy, uh, if if a system is responding to an action purely through a set of well-defined rules without having taken how other observations and knowledge about the state its own states and the state of others.

Observations of the world, then that would be in my opinion autonomous, but I'm trying to agree with possibly getting down rabbit hole here.

[Speaker 1]
Yeah, by following this, we can keep this in mind and going to from where we left, sorry, but coming back to agentina, um, so we have these definitions here.

Yeah, so that is something that. Would not disagree with.

Over time. Maybe this is a bit constraining?

Um, but maybe we should discuss this in a regular meeting to reduce the terminology because we could spend the rest of the day just no, no. Okay,

[Speaker 3]
Yeah, it would be fascinating, but it wasn't a cheap, but also today. Yeah, yeah.

[Speaker 1]
Put just as a

[Speaker 3]
Point of order here. I almost feel like some of these skulls I think are defining what we mean by agents with the web. These things are maybe things that, when are not necessarily established, then we'd want to move forward. So, with that situatedness there, when you think of Agents on the web, it feels like, yes, the agents are automatically situated within a web environment or with a web context, so it feels implicit again. I mean, I don't want to suddenly make all of this stuff implicit explicit, but it feels like it is a it's definitely a characteristic of it, um, a hyper media agent on the web.

[Speaker 1]
It on the?

[Speaker 3]
Are in a flat cheese store, because I feel like this is a property of what we're trying to achieve.

[Speaker 5]
Question

[Speaker 1]
For architectural patterns. We have agents that are situated, so they start from a single entry point. They discover the system they can act, they can perceive, and so on. They can perceive one another because they are part of the same work context, and they can see other agents in that context, so it checks all the boxes of situatedness. Then, if I think of the demo that Mike amundsen was showing in Doc's tool?

Is that he defined? Other agents in the log range. They were just crawling, and then that was it. So arguably, they fited the definition of agent, but they are not necessarily situated.

Llm agents today are not separated in the sense that we are discussing here,

[Speaker 3]
But there's still web agents in our context.

[Speaker 1]
Yeah, yeah, right,

[Speaker 3]
Okay, and

[Speaker 2]
Maybe situations is too strong, and you argued me back with that one.

[Speaker 6]
We give you about

[Speaker 1]
Architecture. Yeah, and those tips should relate to the web sample and potentially the web standards. So, for instance and citizens is a great example here. If you want to build an agent that is situated, what that means is that the agent has to be able to observe the environment if you want it to observe the environment. Here is a set of standards that might be useful to you, web sub pressing description, and so on. So, the AC

[Speaker 2]
Environment, the web, or is it the similarity? So, in the case of micromances, May is the environment was denied. Yeah.

[Speaker 1]
Hybrid environment, but the virtual part there doesn't necessarily mean a computational entity. So, in Mike's case, the lab link itself was an abstraction. So, it was an adaptation layer.

Mike's amaze. My argument would be that they

[Speaker 2]
Were not really situated well in that situation. Amazed by that situation on the web.

[Speaker 1]
Actually. Another way to look at it is the diversity will not embodied.

[Speaker 2]
Sorry, sorry.

[Speaker 1]
Use Google Docs. And then you can see that somebody else is on Google Docs with you, and you can also see where they are in the dock so. You become aware that they're there, so it's it's a sort of embodiment.

[Speaker 2]
You have some sort of manifestation of your presence within the environment, right?

[Speaker 1]
So, so, such that other people can perceive your presence?

[Speaker 3]
This demo didn't, you're saying?

[Speaker 6]
Everest, right? Because we have something to say about how you would achieve them?

[Speaker 1]
Oh well, like, this is a candidate please. It doesn't mean that it's set in strong so we can add it underneath.

[Speaker 2]
Situation itself could be a stronger form of embodiment. A stronger form of situation is where you have embody

[Speaker 1]
Rather

[Speaker 2]
Than being a separate thing. I mean, this is a bit

[Speaker 1]
Interesting because embodiment's case.

But we access it through our telephone, and then we give him access to use our sensors, camera, Etc. Is, is somebody Table on our telephone?

The sensors are here. Actually, shirts are here. Do we have a presence?

[Speaker 2]
So, is it using the data streams, in which case does it have a press

[Speaker 1]
Microphone? I'm speaking to

[Speaker 3]
It. Yes, these sensors on the local device? Yeah, but if the cognition over all of those data streams. Those first steps is almost separate machine so,

[Speaker 1]
But the pieces.

[Speaker 2]
Since it is a sensor.

[Speaker 3]
I, I suppose, the question now becomes, what is the brain of the agent versus? Bill communicable elements. And here, we've got them separate, but I would actually say, arguably,

[Speaker 1]
I don't know if we can call it because essentially any software you have to install or deploy to somewhere. No,

[Speaker 3]
I appreciate what you say. I think I personally would take the sense that the agent is on the server, and it has sensors which are sensing through a remote device through a thin client, but that would be my own personal viewing. Yes,

[Speaker 1]
So do you think that we can call it embodyment?

[Speaker 2]
Yeah, because it senses the information from the real world that you're generating through the camera through that thing. Able to, but is able to act in the world, but then, maybe not. Confusing to

[Speaker 3]
Use the word embodiment here. I think the sedatedness is clear, but the embodiment in the robotics they use it also about morphology. The body, like the form of?

Is

[Speaker 2]
Exactly the same thing as a robot in a way, you know, the Bianca, the brain. You've got the body and the, you know, the robot exists within an environment, and it senses its environment. So, if you're using a phone?

Eyes, so he was human,

[Speaker 1]
So maybe so one suggestion?

[Speaker 3]
Okay, so one

[Speaker 1]
Suggestion, because, um?

Was fun, and we are losing a bit. So, we are, we are becoming more and more abstract. So,

[Speaker 3]
Maybe one suggestion

[Speaker 1]
Would be that we use the demo to illustrate some of these Concepts because the demo essentially shows some of the concepts coming from the mosque Community around that.

[Speaker 3]
I think the demo we requires the counter argument on situatedness embodiment heading here in general.

Separate thing, but I normally think so. I think your your race, a very interesting point where the environment is the web itself.

A resource that, and the environment is something else.

[Speaker 1]
There is also research from the mass Community that can help, so the environment as a first class abstraction, the work of Danny Vines.

With clear-cut design responsibilities where it provides levels of support to the agent. That level of support could be access to the deployment context. The department context could be the web, actually, or what Fabian calls the World Wild Web. So, the heterogeneous web?

Level of support, which is meant to bridge the gap between the agent level of abstraction and its deployment context, interaction, mediation, and so on, so I can see a hypermedia environment as a design space that you can use to provide all these levels of support. I'm not sure I would classify the web itself.

So, it is an environment in the sense, just like the real world is an environment, and everything is an environment. And also, I think that the term environment is a bit overloaded, but again, we are using it as it is defined in the mosque community, so. No, this is just one of his jokes world wild with another worldwide wide web. But the World Wide Web to emphasize the heterogeneity and?

Um, I'm gonna show you a demo of some of the technologies that we developed in, you know, project. Also, together with Antoine and Fabian gando and Olivier bossier and Gustavo, who is online and so on.

So, by the way. Um, and maybe it helps to show business diagrams. So, these are diagrams that come from any vines architectural patterns.

We brought the demo into the discussion because it can help to illustrate the sort of architectural patterns they can help to illustrate. What is the situated hypermedia agent or what it could be?

Um, so what I'm going to do is I'm going to run three nodes that support this distributed virtual hyper media environment.

Could also think of those as mCP servers, so we don't use language agents in this demo, but you could have multiple mCP servers that run some tools that the agent can access.

Some artifacts where the artifacts can also have internal State. They can have their own thread of control. They can do more things than a tool as in agentic AI. So, a tooling agentica is essentially a function called, and that's it. So these are computational entities that can have their own thread of control and so on. The artifacts?

Is, so this would be closer, maybe not. Yeah, okay, I'm gonna stop there. So the exposure happen in the interface that the agents can use, and then for the agents we use what are known as BDI agents. So believe these are intention agents. This is one of the.

And perceive and act on the environment. They have a control Loop.

They have an internal knowledge base, which would be the memory here. Itself is a very simple scenario. Start first, the three nodes.

And yeah. I was concerned for a bit. Now, because I had some problems with Docker previously.

Um, the environment is represented in rdf, so I'm gonna show you in a bit the three nodes. One second, one third one. The web of things in description, which comes up in the group sometimes to describe entities in this environment.

[Speaker 2]
Little and larger?

[Speaker 1]
Yep. Does it work? Okay, so it's a very simple scenario where we have three workspaces. The workspace is just a container for the activity of agents.

Workspace. What that means is that it is a workspace containing a specific artifact that can produce items. The items are just integers, so it's a very simple demo. Then we have a consumption workspace, which has a sync artifact that can consume items. And then we'll have one agent controlling the production workspace that will produce the items, and they have to transfer them to the other workspace, where there is another agent that can consume the the items using the artifact. They will need to use an intermediary buffer. Uh, so then they have to discover this buffer. They have to trans. The production agent has to transfer items from production to the buffer.

For once, they become available. So, it has to be aware when they become available and then transfer them to consumption. If that makes sense, and the

[Speaker 3]
Artifact the problem. Yeah, so it's something intelligent. It's not just a document, sorry, it's. It's a running program architect.

[Speaker 1]
Yes, it's a running program, and then what the framework does. Agents can also create artifacts. They can instantiate the artifacts. You have an artifact template just like a class.

The nations can discover them in the environment and can interact with them, but you can see them as virtual objects, you know. How can you get environment basically?

So, currently, they are isolated. Some links to the hypermedia environment to make them discoverable. After I start the agents.

Um, I'm gonna start the jackhammer application, so these are different components. So, there are three nodes for the environment, and this is the client basically.

[Speaker 3]
So, as the agents discovering the

[Speaker 1]
Same description autonomously, yes, and they perform actions based on the same description. So, then, at front end, they have to compose an HTTP request to interact with the environment.

Ah, that encapsule is that functionality? So this comes back to the patterns that we can consider. What you can see here? Is that Alice and Bob joined their homework space? Uh, to show you a bit the configuration of the project, so you can see here the entry point. So, Alice has one URI as an entry point, which is the production workspace.

Space. The workspace. They actually perform an action to join the workspace and then. Reflected. The workspace through what we call about the artifact, so they are actually embodied such that other agents can discover them.

Go to the oblique representation. We can see that now. The production workspace contains the initial Source artifact that produces items, but it also contains the body artifact of Alice.

And agents can use the body artifact to expose accordances to other regions.

Exactly the case where an agent discovers a robot, and then it exposes five media affordances.

World robot or an artifact?

Workspace. So now, Bob is embodied here. It is part of the workspace. But

[Speaker 3]
The the world, not the way of things. The developer has to kind of be in the middle here to do the action very well, that for that, or

[Speaker 1]
Um, so the developer form, I mean, like, is written by a person, not the

[Speaker 3]
Agents don't discover the upperate senses and do that? Or am I wrong?

[Speaker 1]
Um, so they do discover the affordances, so somebody needs to write the same description usually.

Is a client that can discover a scene description?

So, so essentially, you have a client that discovers hypermedia controls, and then it can use those thing work actions.

I

[Speaker 3]
Misunderstood, so I will correct about it a little bit okay.

[Speaker 1]
If you have questions, yeah. Okay, so, so far, uh, Bob and Alice entered the workspace. You can see here the output from using the same description. Actually, the HTTP request that is being composed.

Species are disconnected. To one another.

[Speaker 4]
Workspace and policies in the other way.

[Speaker 1]
Yes, Alice is in production. Bob is in consumption in the middle. There is a shared workspace, but they cannot discover it yet.

What I'm going to do is I'm going to run a script that adds links between the manufacturing workspace, the parent workspace, and the production and consumption workspace. So, then, I'll have one manufacturing workspace that has three sub workspaces production shared consumption.

Workspace and the buffer artifact. And here, you can also see the perception so. Agents are situated. They continuously perceive the environment as soon as I run the script. They will perceive there are some new workspaces available, and they are going to crawl and discover them.

To transfer items. Is here on the back end. Can

[Speaker 3]
You define what you mean by crawl in this context?

[Speaker 1]
Presentation. The loop. Here, you can see that there is no. Wait, I need to go to the consumption workspace. Essentially, what I did is, I added these triples that, for instance, the consumption workspace is contained in manufacturing. So, now, Bob is going to navigate to manufacturing. It. Now, it says that there are three sub workspaces.

But now we can discover production in shared. Shared workspace. It will discover there. Um. The buffalo artifact. Crawling or navigation in that sense. Gene,

[Speaker 3]
When so, when it discovers these things is because it can identify that there is something that needs to pass, which happens to be a web document or a document in this form, and therefore it's reading through that. Because I think of crawling as in going following links through web pages. Yep, very quickly.

If you're representing this agent through form document, it's then getting a much richer representation of what's possible, what is what it can achieve?

[Speaker 1]
Um, and

[Speaker 3]
In this case, it's seeing that. Oh, there is a new thing, and the definition within a document that describes that is the workspace, and is that what you're doing?

That's

[Speaker 1]
What they mean, and so you

[Speaker 3]
Are following a hype link, and a hyperlink refers to.

[Speaker 1]
Document here would be a representation of the workspace. Yeah, what we call a resource profile? Yeah, so the workspace in itself is a non-information resource, but there is an information resource, which is a description of the workspace that the agent can retrieve. In this case, we're also using descriptions for workspaces.

Interpret the environment.

Yeah,

[Speaker 3]
So just, I'm fully. I fully understand this button agent. It's in a workspace. It can continually retrieve and re-pass that description of that workspace, and so when the view workspace disappear, that description is updated by its parent.

[Speaker 1]
Yep,

[Speaker 3]
And that's what introduces these new links that it can then go.

[Speaker 1]
Yeah, so now, now we come to the architectural port, so I'm gonna close the application. Is it fine?

Node.

Deployment context on the top. You have the interface that is exposed to the agent. The ACT interface. Essentially, we use scene descriptions that expose hypermedia affordances that agents can invoke.

Websub as a sub protocol, you know? Same description.

An agent can observe any resource on the web, so when the agent discovers the workspace, it can subscribe to notifications. Whenever the state of the workspace has changed. And this is what what's happened here.

[Speaker 3]
And then on the client

[Speaker 1]
Side. It is not the agent that does all the low level thing. So, use something like a browser. Application. It will do a diff between the previous state and the current state, and then it just sends updates to the agent. So there is a new workspace available, or yeah.

[Speaker 3]
Is basically two for the

[Speaker 1]
Yes, it's a tool. It's exactly a tool.

So, it's exactly a tool. It's, it's a meta model that has been in the mass Community for some time, so agents and artifacts it's called.

Are typically. That you? Artifact is a richer abstraction. Events and overall properties, so it actually matches very well with the notion of a thing in the web of things. So, if you looked at Elmos, that might actually be more familiar.

Meetings for? It's a framework for authentic AI that uses the same description.

Um, does this help to ground the concepts a bit?

So, one thing that came out in the discussion this morning. So these are mostly the patterns from any vines with with actually no changes. So these are exactly the patterns from his book. One thing that came out in our discussion is that? And by the way, so this follows the uml component language, right? So you have components shared interfaces, required interfaces, ports, and so on. Or patterns that can apply to design any piece of software.

Stands out. If you look at the demo, is that?

Most interested in are network-based architectures for the most part. So, here we would expect to have a web interface, so it's a network based interface. It's not.

Techno platform, which has nothing to do with the web.

And that's it! Um. But one thing that came out is that we would be interested here to have web interfaces. So, for instance, what are the relevant web standards for observing an environment for the sense interface. Web sub link data, notifications, and so on and so forth. Is there something that is missing. Do you need something more then? What are the relevant web standards for acting, you know, having the environment same? Description Hydra.

The pattern for the situated agent? Demo is actually a bit more than that, and maybe it's something interesting to discuss. So, what we have in in the demo is closer to how we use the web, so we as humans don't compose HTTP requests, but we use web browsers and the web browser will encapsulate all the low level logic of handling HTTP requests and so on. That's exactly what happens here. There is a separation of concerns between agents and the autonomous behavior, so this is the logic of the agent.

We could also synthesize plants at runtime, but that's a different story. So, this is a programming language for BDI agents. Exactly! Then the agents are using this Library Giacomo hypermedia, which provides a bunch of artifacts.

Single effect, which is essentially something like a web browser or closer to a tab in a browser, so they have one such sync art effect for every artifact that is discovered in the hypermedia environment. You cannot, in distributed systems terminology, you can see this as a stub. As a client stop, this is an artifact stop. Basically, the web sub single artifact would be an artifact stub that can also receive notifications if the state of the artifact is changed.

Are useful for people. Agents should not have to deal with the low level logic of composing, issuing, and handling HTTP requests.

It's an open question, but so the goal of the discussion would be to see if these patterns. As proposed by identifys are sufficient for our context, or we need something more.

Side, having this sort of. Button that we can use for something like browsers or artifact, sync artifacts, and so on. Would be more precise about network interfaces and so on. Tonight, you wanted to jump.

[Speaker 4]
Agent what is the difference between?

To receive here. It's like synchronous asynchronous.

[Speaker 1]
Um

[Speaker 2]
And receivers for communication. So, if you have a message, if you have something feature ACL or bspl.

Part of a single environment, or it could be a distributed in brand. So,

[Speaker 4]
It is for agent Asian Community.

[Speaker 2]
Yes, yes, yeah, so separate from the sensing and affecting, but he does any of you the idea of?

[Speaker 3]
So, it's going to say the situations have your pattern at the agent pattern. Reminds me a lot of the actual architecture behind Jason itself where Jason has.

Environment,

[Speaker 2]
Yeah. So,

[Speaker 3]
The thing that thing, the

[Speaker 2]
Way we've interpreted this, is that this is not everything is mandatory. So, for example, if you didn't have a communication infrastructure, then you could just have sensing in action.

Tool use mCP. You have an act box.

[Speaker 3]
You don't

[Speaker 2]
Have a sense box at the moment. Very agentic, kind of. I mean, you can say that the mCP tools are also sensors use for sensing in some some extent.

[Speaker 1]
Everything you get as a result of a tool invocation. Yeah, so then

[Speaker 2]
The question

[Speaker 1]
Is, are you just using the ACT interface?

Interface here would employ some sort of asynchronous interaction, which is not the case there, right?

Just use the ACT interface and you would get an observation simply as the result of an action basically.

[Speaker 3]
Almost not wanting to respond because I think trying to fit llm agents Quantified them, qualified them, and then relate them to. This is another days with a bug. Yeah,

[Speaker 1]
Yeah,

[Speaker 3]
Because I mean popular questions.

[Speaker 1]
Actually, we think it's not so far because we discussed this a bit, so this pattern mostly fits. Uh, what was there in the initial pattern and we replaced here was knowledge base, and we replaced this with memory to make it a bit broader.

[Speaker 3]
And then an isolated element that just belongs to a single agent. Or are you using service? Call out for an alarm, which is shared by many, just

[Speaker 1]
Wait. So

[Speaker 3]
Well, it will because the llm may learn from other decisions. Other agents are making and that works not completely

[Speaker 2]
Isolated. Let me add a quick note

[Speaker 1]
Here, so it's not llms, but llm agents.

[Speaker 2]
Very useful and interesting questions, but they're not ones. To an Ln. A set of agents would include and a single lln, I think, could be used behind all the interactions within the whole system.

Be a valid implementation of an energetic system, and

[Speaker 3]
I will wait for offline when we can discuss this.

[Speaker 2]
To my experience, I mean,

[Speaker 3]
No, I appreciate that they raises questions.

[Speaker 2]
I, I haven't seen ones,

[Speaker 3]
Just may ask your one question. Sorry, it may be just a step aside, but first of all, is it possible to have this agent other than agent without memory, considering yes, that all and context as a memory and the second point.

Which are being served to us as llms, yeah. For example, this llm has a deep research capabilities, so it's going to the internet. It's searching something, it uses it, and then returns us. And that's all within the one single llm call. Yeah, so in this case.

By by the vendor, I don't.

[Speaker 2]
It comes out to decision-making capability of the area of the of this thing that we're calling an agent. Yeah, so it's an agent. It might be an agent wrapped in an agent.

[Speaker 1]
Yeah, but yeah, it's

[Speaker 2]
Just decision-making mechanism. How it's achieved is, yeah.

[Speaker 1]
Also make some decisions on the way. Do I need that information? Do I need more information? Do I need to invoke that tool or the other tool. So, for instance, with Claude, you can have different tools that you can configure, like.

Early profiles, and so on. So, I have a tool for dblp. I have a tool for Google Scholar. I just give it a task, and then it decides if they if it needs to use those tools or not, so

[Speaker 4]
It

[Speaker 1]
Would very well fit. Here you have the decision making you have the action.

But that's fine. It still achieves the goals,

[Speaker 3]
And you mean in?

[Speaker 1]
Yeah, yeah. So, in the concrete example that I was given I when I tell, yeah, but we were talking about application. Yeah,

[Speaker 3]
Application your MacBook, so it's basically the some kind of IDE application. Yeah.

Tropic, which is being used in this application. It knows how to call tools, like, read file, write, file, search, suffer, and so on. And maybe?

Being executed by Cloud app on MacBook, not by the model itself. You just do not see it. Yeah,

[Speaker 2]
It clearly stores and says, use that tool. It executes. It all returns it back in the context and then continues the. Uh,

[Speaker 1]
So, yeah,

[Speaker 2]
And you're

[Speaker 3]
Saying. And the llm in this case is being used as a service that's used directly by the agent rather than.

[Speaker 6]
Teacher, because we've got we've got the decision making, or you will wait. And your vehicle says that, well, essentially making requesting perception.

There's a push of sense of information to the decision maker rather than the pool.

[Speaker 1]
Yeah, uh, that's interesting, because in fact, um, in his book, Danny Weiss talks about the behavior based agents and has references to Rodney Brooks.

To the subscription architecture.

[Speaker 3]
I think it can be. I think there a lot of the details hidden in the decision making, because at least that doesn't necessarily map to a BDI agent either, but there are some common elements.

[Speaker 1]
Yeah, it will be. The agent is also behavior-based agent, and it was actually in the middle ground between automated planning and Rodney books.

[Speaker 4]
Please. Communication is connected to decision making. In what way in this icon? That's

[Speaker 1]
A great point. And we were discussing about that. It's not directly connected, but I think it should be. Because

[Speaker 5]
Of its 3D diagram, then you have this field and it's everything is connected, like on the circuit board. Yeah.

[Speaker 1]
So, and yeah, essentially. Everything with the circle is a provided interface. Everything else is the required interface.

I think this is because and this is songs that we should change probably. This is because.

Actually, I don't know why. We need to ask Denny and we, we discussed that we should invite the need one of these. One of the meetings. It would make a lot of sense, uh, but maybe once we have something more concrete for the agenda to talk to him, you're

[Speaker 3]
Proposing to decouple communication from memory with respect to with decision making.

Decisions based on communication, without consultation to the memory or your knowledge.

[Speaker 2]
Actually, you have balls,

[Speaker 3]
You know, but you need both. So, yeah, there's an argument to say communication has to go via memory, because that will

[Speaker 2]
Explain.

[Speaker 3]
Being contradiction with what you already know, but you know, now, know these two facts the space memories.

[Speaker 2]
The memory is logging that we see to the message. Yeah, but it

[Speaker 1]
Doesn't have to be that way. And if I think about the work of vamit the mundindor. They have this protocol adapters that maintain a conversation history, but it's not part of the memory of the agents.

[Speaker 2]
Them? Yes, yes, part of it. Yeah, so it's okay.

[Speaker 1]
Um, how? How do you partition the responsibilities? There would be. If you do that, the agent has to keep in memory all the conversation histories. It can be something that is external. Nothing said it

[Speaker 2]
Has to be permanent. Yeah, so the memory could be added in and removed automatically. You know, based on some?

Because

[Speaker 5]
If I think of a kind of an Asia speak Json model with the animation of beliefs, Communications result in the generational beliefs.

[Speaker 3]
With the existing beliefs, which might generate contradictions, whatever. But that's what then drives that cognition and the idea that you wouldn't. Just like you're starting to not necessarily violate, but you're contradicting many of the standard agent models, which I'm not saying we should, but it.

[Speaker 1]
What you mean? If you have an explicit link between decision making and communication, yeah, without

[Speaker 3]
The use of memory.

[Speaker 1]
Is still there. The question is, if there should be so, the memory. So, the connection between decision making and memory clearly has to be there. I

[Speaker 2]
Don't say one. Is that acting traditionally seen as a way of sending a message, but here in this object, the acting?

So, there needs to be some way. Send that message back and it's come another form of acting so. Having that line back? Message, not the receipt of the message,

[Speaker 1]
Right?

[Speaker 2]
And remember, this is optional. So, in some cases, you could be starting to memory. In other cases, you could not be storing it, and you, you know, both both architectures will be supported by this.

Not about any. It's not a single country object. He's trying to capture a different art, multiple architectural models.

[Speaker 3]
Sent the message because that's going to be a belief that again that you've actually done that communication, because that would then update you arguably, your knowledge about who else should be able to mow the knowledge.

[Speaker 2]
I would agree with you to expect that, but no,

[Speaker 3]
Okay. I'm being a little dogmatic. I must confess.

[Speaker 1]
So, then you would argue that there shouldn't be an explicit link between decision making and communication. No,

[Speaker 2]
I'm saying there should be because there are class of architectures that in that in which that explicit link exists, and particularly in the case of acting and.

[Speaker 3]
Communicate Ralph event. It sets up a goal to say this could be communicated and then the communication component realizes to achieve the goal. It then communicates, so it's a subtle difference. But yeah, no, I'll find that. Okay,

[Speaker 6]
So the emergency situations where direct communication is necessary without invoking memory.

[Speaker 3]
And we, and if we allow the direct communication without memory, then we don't have traces.

[Speaker 6]
Going inside an agent's brain, though you can observe what the agent does.

[Speaker 3]
Jamaican. In regulated Industries, Healthcare in finance. It's it's it's important to understand how the decision was, yeah,

[Speaker 1]
But I guess the answer here would be that adding explicitly from decision making to communication doesn't mean that he cannot use the link from decision making to memory. So,

[Speaker 3]
So this is the company. Yeah,

[Speaker 6]
So serve the agent were to be accountable. We'd have to login section. Yeah,

[Speaker 3]
Okay, got it. It's not accountable.

[Speaker 1]
As well. Um.

Uh, I think you know this book then I?

In our library. Uh, there is also a paper, but the book discusses this in more detail.

Okay, so we are 7 minutes away from the official time for the meeting. So, maybe we can try to summarize a bit with a few next steps? So, first of all, it was really a pleasure to be here all together. And I think this is much more efficient. In online for one hour and then waiting for two weeks. Sure, it's a recording

[Speaker 2]
Stop.

[Speaker 1]
So, I think we had some really ambitious goals for today. We knew that already that we will not be able to address all the questions, but I think we made good progress. Uh, here. Uh, so the next step that I would see is that we can try to pick up this list in the next regular meeting. Then, we can also add the definitions based on the ones that we have from literature, and then we can use the next regular meeting. To consolidate the list, I think it will also help that we step away a bit from the discussion and let things sink in. With the fresh mind in the next regular meeting.

Disseminate this list. Commit one, so let me see. When is the next regular meeting? Would be to disseminate it one week before, maybe?

[Speaker 2]
Our meeting plan of this yesterday recording in progress.

[Speaker 1]
Sorry,

[Speaker 2]
A meeting planned yesterday morning, which was the Friday meeting, so the next will be a Monday meeting, so it's in one, week, two weeks, I think, is

[Speaker 1]
That, yeah, two weeks, um, from Monday in one week, so it's quite close.

Once I am back in the office. Commits to trying to have this ready by Friday evening. So then, at least we have Monday, half a day before the meeting to look over it.

Um, so in any case.

Right. So on the?

[Speaker 3]
Is it

[Speaker 1]
Possible?

Everything, or which is fixed for a living.

Pick two time slots that would cover every one who expressed their availability.

People coming from different time zones, so I'm Stephen in New Zealand. We also have well if Mike could join also. Could be impossible to find a good time slot. Uh, in California. So, then we have these two time slots that try to cover most people. And okay, the aim is that you can join at least once every two meetings. Um. Because a little bit complicated for me Monday. Your wife, my son, is going out from school. Yeah, yeah, I have to meet him.

It works for everyone, but this is what, but we're gonna run the poll again.

So, you know, we'll run it again from the beginning of next year. That makes sense.

Okay, so this would be a concrete action item. I will coordinate with Ram such that we add the definitions, and we have a proposal for the list.

[Speaker 3]
In this list, there are things that were clearly accepted by everyone, so some of them were a little bit discussed and. A little bit controversial. Yep.

I, I don't know if we can do that, but it would be good to be able to.

Uh, to document the discussions and the arguments, and also because we are, we are just 12 people and. If this has the potential to be standardized for the web, it's it's not about these 12 people who mostly agree on things.

Yeah, so it would be good to to be able to to. Trace how? How is this thing? Uh, how did it end in this list?

[Speaker 2]
The

[Speaker 1]
Meeting notes. Look like with this

[Speaker 3]
Ai.

[Speaker 1]
Yeah, so we'll have to see, but

[Speaker 3]
It's important that that we, we know that they are not at the same level of agreement. Yes, of course,

[Speaker 1]
Um.

[Speaker 3]
Mmm,

[Speaker 1]
It's summarized,

[Speaker 3]
But isn't that okay if I were to look at those exactly and tell you what we've agreed on? And I

[Speaker 1]
Think from the discussion, and I just did this a bit more, so I would move this as perhaps one of the main items for the next meeting.

Not appear in the list.

Because it seems like we agree that accountability, actually, Stephen was saying that it's a functional property, not a non-functional property.

Closer to a functional probably.

Um, so I think we can agree that we are not necessarily in agreement on all of them, and then we can review them in the next meeting.

[Speaker 2]
We can sort of will eventually reach a consensus film up which one should be on the list.

[Speaker 1]
Yep, that will

[Speaker 2]
Be trying to sort of. Try and try to remove them now.

[Speaker 1]
Yep,

[Speaker 2]
Based in no Universal, just try and keep fighting for them. Whoever, you know, arguing over them until we come to a consensus that really no that doesn't fit?

I look back over the did different definition of design goals.

See on the end because it's here is listed as a design goal of dids and.

And not discuss it now more, but I've come with the definition and we can discuss it in the next meeting.

In terms of openness, there's common features put it there for now, and I don't open another discussion because I know it's time to finish, but to be honest, I would also keep opening

[Speaker 1]
Some release because I'm not sure it is covered by all everything else. So,

[Speaker 2]
Yeah, in fact, we

[Speaker 1]
Said that instead of openness, we added.

Captures everything with openness. I would put it actually like this because these two are related.

[Speaker 2]
Yeah, I mean, that's why I was saying because I mean, discoverability potentially is another aspect of openness that we hadn't considered. The other

[Speaker 1]
Three are concerned. Yeah, so, for instance, for instance, evolve Mobility. I see this as something that is necessary if we talk about openness. Than a probability.

[Speaker 6]
Is heterogeneity

[Speaker 1]
Also part about this? Yes,

[Speaker 2]
An extensibility, no? Yeah.

[Speaker 1]
Right. We took it out of the list and replaced with these three, but in fact, opens is a bit. So, it, it implies the three, but it's a bit more maybe.

[Speaker 3]
Okay, so.

[Speaker 1]
Thanks everyone! This is the action item for next meeting. This will be the agenda for the next meeting. And then we got some input on the architectural patterns as well. But yeah, we'll need a meeting for that. To advance Jeremy, I

[Speaker 8]
Have a question, this is list. How will it be provenly way to provide Asian friendly speed pack as well on your list?

[Speaker 1]
Yeah, so I think we'll put it in the report

[Speaker 2]
On the branch

[Speaker 1]
For the.

Definition

[Speaker 2]
Will bring it to the next meeting. We'll email it to us if you can't attend. Yeah, so we let's get as much viewpoints on this. Yeah, so we can really sort of try and get it finished. 
 ,  
Sincerely yours, Maxim Ilyin
